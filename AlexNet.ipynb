{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnx2kavJbj7PXYBJ+GAEri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karma-os/DeepLearningImplementation/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3pHfRUvvaqn"
      },
      "source": [
        "# Alexnet 구현해보기\n",
        "\n",
        "\n",
        "- CIFAR 10이나 Fashion-mnist 로 확장해보기\n",
        "- 일단은 이대로 push\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62a1WcdCv947"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "\n",
        "#For optimizing\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4X5Vh7vAm-x"
      },
      "source": [
        "# Image Preprocessing 하는 augmentor 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2sLTmIpv9-r",
        "outputId": "cb0bb247-bd22-424f-bed0-f8469bcaa53d"
      },
      "source": [
        "def alexnet_piepeline():\n",
        "    \"\"\"\n",
        "    Initially, the pipeline flow should be . . .\n",
        "\n",
        "    [1] Data Preprocessing :: ILSVRC data를 dataloader에 넣어서 data_generator 생성\n",
        "        - augmentor는 albumentation의 horizontal_flip + randomcropresize + fancyPCA 이용\n",
        "\n",
        "    [2] create_alexnet을 이용해서 AlexNet 모델을 생성\n",
        "        - LRN layer는 BN layer로 대체\n",
        "\n",
        "    [3] model compile, fit 시 \n",
        "    optimizer=SGD(lr=0.01, momentum = 0.9, decay = 5 * 1e-4), loss='categorical_crossentropy', metrics=['accuracy']) 의 느낌으로 진행해야.\n",
        "\n",
        "    #Learning Rate Scheduler\n",
        "    rlr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=1, mode='min')\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "def create_alexnet():\n",
        "    \"\"\"\n",
        "    AlexNet consists of 5 blocks.\n",
        "\n",
        "    [Feature Extraction Block]\n",
        "    block 1,2: Convolution -> LRN -> Maxpooling\n",
        "    block 3,4,5 : Convolution, with padding \"same\"\n",
        "\n",
        "    [Classifier Block]\n",
        "    Dropout -> Dense -> Dropout -> Dense\n",
        "\n",
        "    issue:\n",
        "    [0] Weight/ Bias Initializations, validation callbacks not applied\n",
        "    [1] In PyTorch Implementation, input_size is different \n",
        "    [2] There is no LRN code in Keras. (PyTorch) \n",
        "        Used BatchNormalization instead.\n",
        "    [3] I've not checked GPU implementation code and whether it is to check \n",
        "    [4] See Ref of pytorch libary\n",
        "\n",
        "\n",
        "        -\"One weird trick for parallelizing convolutional neural networks.\"\n",
        "        (https://arxiv.org/abs/1404.5997)\n",
        "    \"\"\"\n",
        "\n",
        "    input_tensor = Input(shape = (227,227,3), name=\"Alexnet_input\")\n",
        "\n",
        "    #Feature Extractor\n",
        "\n",
        "    ##Block 1\n",
        "    x = Conv2D(filters = 96, kernel_size = 11, strides=4, activation = \"relu\" ,name=\"conv1\")(input_tensor)\n",
        "    x = BatchNormalization(name= \"Instead_LRN_1\")(x)\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides = 2, name=\"pool1\")(x)\n",
        "\n",
        "    ## Block 2\n",
        "    x = Conv2D(filters = 256, kernel_size= 5, activation=\"relu\", padding=\"same\", name=\"conv2\")(x)\n",
        "    x = BatchNormalization(name= \"Instead_LRN_2\")(x)\n",
        "    x =  MaxPooling2D(pool_size = (2,2), name=\"pool2\")(x)\n",
        "\n",
        "    ## Block 3~5\n",
        "    x = Conv2D(filters = 384, kernel_size = 3, activation = \"relu\", padding = \"same\", name = \"conv3\")(x)\n",
        "\n",
        "    x = Conv2D(filters = 384, kernel_size = 3, activation = \"relu\", padding = \"same\", name = \"conv4\")(x) #이래야 사이즈 보존\n",
        " \n",
        "    x = Conv2D(filters = 256, kernel_size = 3, activation = \"relu\", padding = \"same\", name = \"conv5\")(x)\n",
        " \n",
        "    x = Flatten(name=\"Flatten\")(x)\n",
        "\n",
        "\n",
        "    #Classifier\n",
        "\n",
        "    x = Dropout(rate = 0.5)(x)\n",
        "\n",
        "    x = Dense(4096, name=\"FC1\", activation = \"relu\")(x)\n",
        "\n",
        "    x = Dropout(rate = 0.5, )(x)\n",
        "\n",
        "    x = Dense(4096, name=\"FC2\")(x)\n",
        "\n",
        "    output = Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs = input_tensor, outputs = output, name= \"Alexnet_Practice\")\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_alexnet()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Alexnet_Practice\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Alexnet_input (InputLayer)   [(None, 227, 227, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "Instead_LRN_1 (BatchNormaliz (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "Instead_LRN_2 (BatchNormaliz (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 43264)             0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 43264)             0         \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 4096)              177213440 \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "FC2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 197,784,330\n",
            "Trainable params: 197,783,626\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2257_EL_v-Rj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}